{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/mjozwiak/mgr_experiments\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from functools import wraps\n",
    "from itertools import product\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "from graph_neurawkes.experiments import calculate_everything\n",
    "from graph_neurawkes.data.edgelist_data import utils as edge_utils\n",
    "from graph_neurawkes.src.models import Neurawkes, GraphNeurawkes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_list(df):\n",
    "    return [(int(s), int(r), t) for s,r,t in df.values.tolist()]\n",
    "\n",
    "def reset_tf_graph_decorator(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        tf.reset_default_graph()\n",
    "        return func(*args, **kwargs)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_RATIO = 0.2\n",
    "PRED_RATIO = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fb-forum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH_FB = 'graph_neurawkes/data/edgelist_data/fb-forum/data.csv'\n",
    "GAP_SIZE_FB = 5000\n",
    "NUM_VERTICES_FB = 899\n",
    "\n",
    "SAVE_PATH_FULL_FB = 'graph_neurawkes/saves/gnh_fb-forum/1'\n",
    "SAVE_PATH_NAIVE_FB = 'graph_neurawkes/saves/nh_fb-forum/naive_basic_fb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@reset_tf_graph_decorator\n",
    "def get_gnh_model_fb():\n",
    "    return GraphNeurawkes(64, NUM_VERTICES_FB, 50, True)\n",
    "\n",
    "@reset_tf_graph_decorator\n",
    "def get_nh_model_fb():\n",
    "    return Neurawkes(64, NUM_VERTICES_FB ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Radoslaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH_RAD = 'graph_neurawkes/data/edgelist_data/ia-radoslaw-email/data.csv'\n",
    "GAP_SIZE_RAD = 45000\n",
    "NUM_VERTICES_RAD = 167\n",
    "\n",
    "SAVE_PATH_FULL_RAD = 'graph_neurawkes/saves/gnh_radoslaw/25'\n",
    "SAVE_PATH_NAIVE_RAD = 'graph_neurawkes/saves/nh_radoslaw/naive_basic_radoslaw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@reset_tf_graph_decorator\n",
    "def get_gnh_model_radoslaw():\n",
    "    return GraphNeurawkes(64, NUM_VERTICES_RAD, 50, True)\n",
    "\n",
    "@reset_tf_graph_decorator\n",
    "def get_nh_model_radoslaw():\n",
    "    return Neurawkes(64, NUM_VERTICES_RAD ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypertext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH_HYP = 'graph_neurawkes/data/edgelist_data/ia-contacts_hypertext2009/data.csv'\n",
    "GAP_SIZE_HYP = 75\n",
    "NUM_VERTICES_HYP = 113\n",
    "\n",
    "SAVE_PATH_FULL_HYP = 'graph_neurawkes/saves/gnh_hypertext/13'\n",
    "SAVE_PATH_NAIVE_HYP = 'graph_neurawkes/saves/nh_hypertext/naive_basic_ia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@reset_tf_graph_decorator\n",
    "def get_gnh_model_hypertext():\n",
    "    return GraphNeurawkes(64, NUM_VERTICES_HYP, 50, False)\n",
    "    \n",
    "@reset_tf_graph_decorator\n",
    "def get_nh_model_hypertext():\n",
    "    return Neurawkes(64, NUM_VERTICES_HYP ** 2 - NUM_VERTICES_HYP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_longest_val_sequence(data_path, gap_size):\n",
    "    df = edge_utils._get_df_from_csv(data_path)\n",
    "    num_ids = max(df.sender.max(), df.recipient.max()) + 1\n",
    "\n",
    "    dfs = edge_utils.cut_on_big_gaps(df, gap_size)\n",
    "    val_count = int(len(dfs) * VAL_RATIO)\n",
    "    val_dfs = dfs[:val_count]\n",
    "    \n",
    "    return df_to_list(max(val_dfs, key=lambda d: len(d)))\n",
    "\n",
    "def split_seq_into_seed_and_true(seq):\n",
    "    true_len = int(len(seq) * PRED_RATIO)\n",
    "    seed_seq, true_seq = seq[:-true_len], seq[-true_len:]\n",
    "    return seed_seq, true_seq\n",
    "\n",
    "def generate_sequence(seed_seq, true_seq, mode, model, save_path):\n",
    "    if mode == 'length':\n",
    "        pred_seq = model.generate(saved_path=save_path, seed=seed_seq, max_events=len(true_seq))\n",
    "    elif mode == 'duration':\n",
    "        pred_seq = model.generate(saved_path=save_path, seed=seed_seq, max_time=true_seq[-1][2])\n",
    "\n",
    "    return pred_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THE MEAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard-esque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_SPEC = [\n",
    "    ('hyper', DATA_PATH_HYP, GAP_SIZE_HYP, get_gnh_model_hypertext, SAVE_PATH_FULL_HYP, get_nh_model_hypertext, SAVE_PATH_NAIVE_HYP),\n",
    "    ('radoslaw', DATA_PATH_RAD, GAP_SIZE_RAD, get_gnh_model_radoslaw, SAVE_PATH_FULL_RAD, get_nh_model_radoslaw, SAVE_PATH_NAIVE_RAD),\n",
    "    ('fb', DATA_PATH_FB, GAP_SIZE_FB, get_gnh_model_fb, SAVE_PATH_FULL_FB, get_nh_model_fb, SAVE_PATH_NAIVE_FB)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, data_path, gap_size, gnh_model_func, full_savepath, nh_model_func, naive_savepath in EXPERIMENT_SPEC:\n",
    "    val_seq = get_longest_val_sequence(data_path, gap_size)\n",
    "    seed_seq, true_seq = split_seq_into_seed_and_true(val_seq)\n",
    "\n",
    "    for gen_mode, model_mode in product(['duration', 'length'], ['full', 'naive']):\n",
    "        if model_mode == 'full':\n",
    "            model_func = gnh_model_func\n",
    "            savepath = full_savepath\n",
    "        else:\n",
    "            model_func = nh_model_func\n",
    "            savepath = naive_savepath\n",
    "\n",
    "        generated_seq = generate_sequence(seed_seq, true_seq, gen_mode, model_func(), savepath)\n",
    "        \n",
    "        with open(f'graph_neurawkes/experiments/jaccard_results/{name}_{model_mode}_{gen_mode}.txt', 'a') as f:\n",
    "            f.write(json.dumps(generate_sequence) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic tests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
